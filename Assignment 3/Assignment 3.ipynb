{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/profmcnich/example_notebook/blob/main/a3_sample_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\\(\\^Be sure to update this button to point to your notebook instead of the sample notebook\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 15 rows of the data \n",
      "     Temperature °C  Mols KCL     Size nm^3\n",
      "0              469       647  6.244743e+05\n",
      "1              403       694  5.779610e+05\n",
      "2              302       975  6.196847e+05\n",
      "3              779       916  1.460449e+06\n",
      "4              901        18  4.325726e+04\n",
      "5              545       637  7.124634e+05\n",
      "6              660       519  7.006960e+05\n",
      "7              143       869  2.718260e+05\n",
      "8               89       461  8.919803e+04\n",
      "9              294       776  4.770210e+05\n",
      "10             991       117  2.441771e+05\n",
      "11             307       781  5.006455e+05\n",
      "12             206        70  3.145200e+04\n",
      "13             437       599  5.390215e+05\n",
      "14             566        75  9.185271e+04\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Temperature °C  1000 non-null   int64  \n",
      " 1   Mols KCL        1000 non-null   int64  \n",
      " 2   Size nm^3       1000 non-null   float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 23.6 KB\n",
      "Table summary \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# Using pandas load the dataset (load remotely, not locally)\n",
    "# Output the first 15 rows of the data\n",
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "df = pd.read_csv(\"science_data_large.csv\")\n",
    "print('First 15 rows of the data \\n',df.head(15))\n",
    "print() # new line\n",
    "print('Table summary \\n',df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the pandas dataset and split it into our features (X) and label (y)\n",
    "X = df[['Temperature °C', 'Mols KCL']].to_numpy()\n",
    "Y = df['Size nm^3'].to_numpy()\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.90, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Perform a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [ 134891.57109752  566848.1770532  1241137.60975794  -24367.1696409\n",
      "  -70657.3340248   384956.44708746  467392.47066236  960873.69862144\n",
      "    8407.39619923   51611.35989487  838231.36519831 1232720.46674085\n",
      "  901563.3931183  -118835.20674597  188176.20244545 1158467.7057509\n",
      "  665263.26735435  560560.92590561  163940.53886357  469055.93661764\n",
      " 1419180.64745835  -84401.29716064  555956.53417346 1401489.68980634\n",
      "  450621.8221688  1161403.05700777   45784.96014151  408948.47482721\n",
      "  421868.97874553  645969.69402768  467893.44392697  208517.41869172\n",
      " 1438187.73449241  708330.20055877 1400047.62029314  711132.70221441\n",
      "  942380.06884206 1116186.8384737  1257396.19462681  189369.12027644\n",
      "   71374.08771584  870102.22808014   94087.37936383  407174.28131093\n",
      "  271473.01984826  388791.32041263  237873.60116061  790013.37060675\n",
      "  112125.67358907  512139.47602221  905252.99153208 -163237.6627926\n",
      " 1056768.59266956  757865.71816238  422587.22624213  838109.54727724\n",
      " 1168808.55676556  420476.72783278  562454.20876288 1196155.27165602\n",
      " 1141958.63424972 -205320.64929795 -193313.545068    882065.02954971\n",
      " -233968.28100031 1111316.74753909  125465.51340122  862352.1203292\n",
      "  495379.97656865 -260706.08232516  463075.95885281  636857.7605043\n",
      "  958770.10968217  514388.39855279  139911.11783352  874190.37529761\n",
      "  634698.83712449 1003517.17372194  536824.90063825  402129.82527471\n",
      " 1095143.98093098  752354.83621194  438989.75107231  175035.63703514\n",
      "  339707.01615308  -94234.2067607   749168.99832276  802198.96214839\n",
      "  767320.80736899   79090.92438656   72706.82329805  325614.2641341\n",
      "  424739.29883178   38884.61453832  264437.03738384 1344491.9443744\n",
      "  747405.89516655  321578.72277709  473270.08264618  772305.80675459]\n",
      "Score: 0.8571870071495865\n",
      "coefficent: [ 863.58108791 1006.12741921]\n",
      "intercept: -400305.9133335327\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to train a model on the training set\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "# Create a sample datapoint and predict the output of that sample with the trained model\n",
    "print(f\"Prediction: {reg.predict(X_test)}\")\n",
    "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
    "print(f\"Score: {reg.score(X_train,Y_train)}\")\n",
    "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
    "print(f\"coefficent: {reg.coef_}\")\n",
    "print(f\"intercept: {reg.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation: $Size\\ nm^3 = m_1 * Temperature\\ °C  + m_2 * Mols\\ KCL + intercept$\n",
    " $Size\\ nm^3 = 863.58108791 * Temperature\\ °C  + 1006.12741921 * Mols\\ KCL - 400305.9133335327$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Use Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83 accuracy with a standard deviation of 0.09\n"
     ]
    }
   ],
   "source": [
    "# Use the cross_val_score function to repeat your experiment across many shuffles of the data\n",
    "scores = cross_val_score(reg, X_train, Y_train, cv = 50)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "# Report on their finding and their significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Using Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0\n",
      "coefficent: [-1.67092717e-06 -4.59112302e-07  5.99999995e+00 -6.85973218e-07\n",
      "  2.15546316e-08  6.66666650e-01  9.52381068e-03 -6.11407661e-11\n",
      "  5.99999940e+00 -1.16888293e-06 -9.97037660e-09  6.66666675e-01\n",
      "  9.52381067e-03 -9.96993115e-09  6.66666675e-01 -2.28827814e-12\n",
      " -1.26892972e-11  1.10935228e-10  9.52381068e-03  1.40704083e-11\n",
      " -1.12939135e-10 -4.21785059e-12  9.72290744e-16 -9.28401615e-16\n",
      "  2.38291600e-11 -2.38291617e-11  1.80924214e-15  1.70218563e-15]\n",
      "intercept: 0.00045260752085596323\n"
     ]
    }
   ],
   "source": [
    "# Using the PolynomialFeatures library perform another regression on an augmented dataset of degree 2\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.fit_transform(X_test)\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "print(f\"Score: {model.score(X_train, Y_train)}\")\n",
    "print(f\"coefficent: {model.coef_}\")\n",
    "print(f\"intercept: {model.intercept_}\")\n",
    "# Report on the metrics and output the resultant equation as you did in Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
